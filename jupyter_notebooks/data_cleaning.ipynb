{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ecdcff",
   "metadata": {},
   "source": [
    "## Predictive Modeling of Food Deserts: Data Cleaning\n",
    "### TDA Food Desert Project: Data Exploration & Alternative Data Sources\n",
    "This notebook explores dataset relationships and identifies tract-level food environment data to supplement county-level FEA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1754a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7541db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1: EXPLORE DATASET RELATIONSHIPS\n",
    "def explore_fea_county_coverage(fea_df, county_fips_col, merged_df):\n",
    "    \"\"\"\n",
    "    Analyze how many tracts share the same county-level FEA data.\n",
    "    This shows the data resolution problem.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"FOOD ENVIRONMENT ATLAS COVERAGE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # count tracts per county\n",
    "    tracts_per_county = merged_df.groupby('COUNTYFIPS').size()\n",
    "    \n",
    "    print(f\"\\nTotal counties: {len(tracts_per_county)}\")\n",
    "    print(f\"Total tracts: {len(merged_df)}\")\n",
    "    print(f\"Avg tracts per county: {tracts_per_county.mean():.1f}\")\n",
    "    print(f\"Median tracts per county: {tracts_per_county.median():.0f}\")\n",
    "    \n",
    "    print(\"\\nDistribution of tracts per county:\")\n",
    "    print(tracts_per_county.describe())\n",
    "    \n",
    "    # Counties with most tracts\n",
    "    print(\"\\nTop 10 counties by tract count:\")\n",
    "    top_counties = tracts_per_county.nlargest(10)\n",
    "    for fips, count in top_counties.items():\n",
    "        county_name = merged_df[merged_df['COUNTYFIPS']==fips]['County name'].iloc[0]\n",
    "        print(f\"  {fips} ({county_name}): {count} tracts\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(tracts_per_county, bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Number of Tracts per County')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Tract Count per County')\n",
    "    plt.axvline(tracts_per_county.mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {tracts_per_county.mean():.1f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(tracts_per_county, vert=True)\n",
    "    plt.ylabel('Tracts per County')\n",
    "    plt.title('Tract Count Distribution (Boxplot)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return tracts_per_county\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_within_county_variation(merged_df):\n",
    "    \"\"\"\n",
    "    Analyze variation of tract-level variables WITHIN counties.\n",
    "    High variation suggests county-level FEA data may be insufficient.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"WITHIN-COUNTY VARIATION ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Variables to analyze\n",
    "    tract_vars = ['median_income', 'poverty_rate', 'population']\n",
    "    tract_vars = [v for v in tract_vars if v in merged_df.columns]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for var in tract_vars:\n",
    "        # Calculate coefficient of variation within each county\n",
    "        county_stats = merged_df.groupby('COUNTYFIPS')[var].agg([\n",
    "            ('mean', 'mean'),\n",
    "            ('std', 'std'),\n",
    "            ('cv', lambda x: x.std() / x.mean() if x.mean() != 0 else 0),\n",
    "            ('range', lambda x: x.max() - x.min())\n",
    "        ])\n",
    "        \n",
    "        results[var] = county_stats\n",
    "        \n",
    "        print(f\"\\n{var.upper()}:\")\n",
    "        print(f\"  Avg within-county CV: {county_stats['cv'].mean():.3f}\")\n",
    "        print(f\"  Median within-county CV: {county_stats['cv'].median():.3f}\")\n",
    "        print(f\"  Counties with high variation (CV > 0.5): {(county_stats['cv'] > 0.5).sum()}\")\n",
    "    \n",
    "    # visualize\n",
    "    fig, axes = plt.subplots(1, len(tract_vars), figsize=(5*len(tract_vars), 4))\n",
    "    if len(tract_vars) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, var in enumerate(tract_vars):\n",
    "        axes[idx].hist(results[var]['cv'].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_xlabel('Coefficient of Variation')\n",
    "        axes[idx].set_ylabel('Number of Counties')\n",
    "        axes[idx].set_title(f'Within-County CV: {var}')\n",
    "        axes[idx].axvline(0.5, color='red', linestyle='--', label='High variation threshold')\n",
    "        axes[idx].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e690396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_food_desert_indicators(merged_df):\n",
    "    \"\"\"\n",
    "    Identify which FEA variables are most relevant for food desert analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FOOD DESERT INDICATOR IDENTIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Key food access indicators in FEA (adjust based on your actual columns)\n",
    "    food_access_keywords = [\n",
    "        'snap', 'grocery', 'supermarket', 'store', 'access',\n",
    "        'desert', 'distance', 'vehicle', 'low_income', 'poverty',\n",
    "        'wic', 'assistance', 'market', 'fresh', 'healthy'\n",
    "    ]\n",
    "    \n",
    "    # Find relevant columns\n",
    "    relevant_cols = []\n",
    "    for col in merged_df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if any(keyword in col_lower for keyword in food_access_keywords):\n",
    "            relevant_cols.append(col)\n",
    "    \n",
    "    print(f\"\\nFound {len(relevant_cols)} potential food access indicators:\")\n",
    "    \n",
    "    # Calculate completeness and basic stats\n",
    "    indicator_stats = []\n",
    "    for col in relevant_cols:\n",
    "        non_null = merged_df[col].notna().sum()\n",
    "        pct_complete = (non_null / len(merged_df)) * 100\n",
    "        \n",
    "        try:\n",
    "            numeric_vals = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "            mean_val = numeric_vals.mean()\n",
    "            std_val = numeric_vals.std()\n",
    "            indicator_stats.append({\n",
    "                'Indicator': col,\n",
    "                'Completeness': pct_complete,\n",
    "                'Mean': mean_val,\n",
    "                'Std': std_val\n",
    "            })\n",
    "        except:\n",
    "            indicator_stats.append({\n",
    "                'Indicator': col,\n",
    "                'Completeness': pct_complete,\n",
    "                'Mean': None,\n",
    "                'Std': None\n",
    "            })\n",
    "    \n",
    "    stats_df = pd.DataFrame(indicator_stats).sort_values('Completeness', ascending=False)\n",
    "    print(\"\\nTop 15 indicators by data completeness:\")\n",
    "    print(stats_df.head(15).to_string(index=False))\n",
    "    \n",
    "    return stats_df, relevant_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e21639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: ALTERNATIVE TRACT-LEVEL DATA SOURCES\n",
    "\n",
    "def generate_tract_level_recommendations():\n",
    "    \"\"\"\n",
    "    Provide comprehensive list of tract-level food environment data sources.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ALTERNATIVE TRACT-LEVEL DATA SOURCES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sources = {\n",
    "        \"1. USDA Food Access Research Atlas\": {\n",
    "            \"Description\": \"Tract-level food access indicators\",\n",
    "            \"URL\": \"https://www.ers.usda.gov/data-products/food-access-research-atlas/\",\n",
    "            \"Key Variables\": [\n",
    "                \"- Low access tracts (0.5 or 1 mile from supermarket)\",\n",
    "                \"- Low income & low access population\",\n",
    "                \"- Vehicle access rates\",\n",
    "                \"- SNAP authorized stores count\",\n",
    "                \"- Distance to nearest supermarket\"\n",
    "            ],\n",
    "            \"Format\": \"CSV/Excel with tract FIPS codes\",\n",
    "            \"Update Frequency\": \"Periodic (check for latest year)\",\n",
    "            \"Integration\": \"Direct merge on GEOID\"\n",
    "        },\n",
    "        \n",
    "        \"2. OpenStreetMap POI Data\": {\n",
    "            \"Description\": \"Crowdsourced point-of-interest data for food outlets\",\n",
    "            \"URL\": \"https://www.openstreetmap.org/\",\n",
    "            \"Key Variables\": [\n",
    "                \"- Grocery store locations (geocoded)\",\n",
    "                \"- Convenience store locations\",\n",
    "                \"- Restaurant locations by type\",\n",
    "                \"- Farmer's market locations\"\n",
    "            ],\n",
    "            \"Format\": \"Requires processing (Overpass API or extracts)\",\n",
    "            \"Update Frequency\": \"Real-time community updates\",\n",
    "            \"Integration\": \"Spatial join to tracts; requires GIS processing\",\n",
    "            \"Tools\": \"OSMnx Python library, QGIS\"\n",
    "        },\n",
    "        \n",
    "        \"3. Google Places API\": { # too computationally expensive for this project\n",
    "            \"Description\": \"Current food retail locations\",\n",
    "            \"URL\": \"https://developers.google.com/maps/documentation/places/web-service\",\n",
    "            \"Key Variables\": [\n",
    "                \"- Supermarket locations\",\n",
    "                \"- Grocery store locations\",\n",
    "                \"- Restaurant locations\",\n",
    "                \"- Ratings and business hours\"\n",
    "            ],\n",
    "            \"Format\": \"API (JSON)\",\n",
    "            \"Update Frequency\": \"Real-time\",\n",
    "            \"Integration\": \"Query by tract centroid + radius; aggregate counts\",\n",
    "            \"Cost\": \"Free tier available; pay per request beyond limit\"\n",
    "        },\n",
    "        \n",
    "        \"7. USDA SNAP Retailer Locator\": {\n",
    "            \"Description\": \"Locations of SNAP-authorized retailers\",\n",
    "            \"URL\": \"https://www.fns.usda.gov/snap/retailer-locator\",\n",
    "            \"Key Variables\": [\n",
    "                \"- SNAP store locations by type\",\n",
    "                \"- Store authorization status\"\n",
    "            ],\n",
    "            \"Format\": \"Searchable database; may require scraping or FOIA request\",\n",
    "            \"Update Frequency\": \"Regular updates\",\n",
    "            \"Integration\": \"Geocode addresses, spatial join to tracts\"\n",
    "        },\n",
    "        \n",
    "        \"8. ACS Table B22001\": {\n",
    "            \"Description\": \"Receipt of Food Stamps/SNAP by tract\",\n",
    "            \"URL\": \"https://data.census.gov/\",\n",
    "            \"Key Variables\": [\n",
    "                \"- Households receiving SNAP benefits\",\n",
    "                \"- SNAP participation rate\"\n",
    "            ],\n",
    "            \"Format\": \"Census API or bulk download\",\n",
    "            \"Update Frequency\": \"Annual (5-year estimates)\",\n",
    "            \"Integration\": \"Already in ACS; look for table B22001\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for source_name, details in sources.items():\n",
    "        print(f\"\\n{source_name}\")\n",
    "        print(\"-\" * 70)\n",
    "        for key, value in details.items():\n",
    "            if isinstance(value, list):\n",
    "                print(f\"{key}:\")\n",
    "                for item in value:\n",
    "                    print(f\"  {item}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "    \n",
    "    return sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_synthetic_tract_features(merged_df):\n",
    "    \"\"\"\n",
    "    Create tract-level proxies when direct food access data unavailable.\n",
    "    Uses existing socioeconomic and demographic data.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SYNTHETIC TRACT-LEVEL FEATURE ENGINEERING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = merged_df.copy()\n",
    "    \n",
    "    # 1. urbanicity proxy (based on population density)\n",
    "    # 2029 data contains urban column denoted by 1- urban area, 0 - not urban\n",
    "    if 'density' in df.columns:\n",
    "        df['urbanicity_score'] = pd.cut(\n",
    "            df['density'],\n",
    "            bins=[0, 1000, 4000, 10000, np.inf],\n",
    "            labels=['Rural', 'Suburban', 'Urban', 'Dense_Urban']\n",
    "        )\n",
    "        print(\"✓ Created urbanicity_score (based on population density)\")\n",
    "    \n",
    "    # 2. Economic disadvantage\n",
    "    if 'poverty_rate' in df.columns and 'median_income' in df.columns:\n",
    "        # Normalize both to 0-1 scale\n",
    "        poverty_norm = (df['poverty_rate'] - df['poverty_rate'].min()) / \\\n",
    "                    (df['poverty_rate'].max() - df['poverty_rate'].min())\n",
    "        income_norm = 1 - ((df['median_income'] - df['median_income'].min()) / \\\n",
    "                        (df['median_income'].max() - df['median_income'].min()))\n",
    "        \n",
    "        df['economic_disadvantage'] = (poverty_norm + income_norm) / 2\n",
    "        print(\"✓ Created economic_disadvantage (poverty + low income composite)\")\n",
    "    \n",
    "    # 3. Food desert risk score (composite of available factors)\n",
    "    risk_components = []\n",
    "    \n",
    "    if 'poverty_rate' in df.columns:\n",
    "        risk_components.append('poverty_rate')\n",
    "    \n",
    "    if 'vehicle_access' in df.columns:  # if available from ACS\n",
    "        risk_components.append('vehicle_access')\n",
    "        # vehicle access is important as it determines things like travel times to stores which affects food access\n",
    "    \n",
    "    if 'density' in df.columns:\n",
    "        # Low density increases risk in rural areas - may have longer travel time to stores \n",
    "        df['low_density_risk'] = 1 / (df['density'] + 1)  # inverse relationship\n",
    "        risk_components.append('low_density_risk')\n",
    "    \n",
    "    if len(risk_components) > 0:\n",
    "        # normalize and average\n",
    "        risk_normalized = df[risk_components].apply(\n",
    "            lambda x: (x - x.min()) / (x.max() - x.min()) if x.std() > 0 else 0\n",
    "        )\n",
    "        df['food_desert_risk_score'] = risk_normalized.mean(axis=1)\n",
    "        print(f\"✓ Created food_desert_risk_score (using {len(risk_components)} components)\")\n",
    "    \n",
    "    # 4. neighborhood disadvantage index - combinign fators for each neighborhodd that will dtermine how at risk the neighborhood is to food insecurity\n",
    "    socioeconomic_vars = ['poverty_rate', 'median_income', 'unemployment_rate']\n",
    "    available_vars = [v for v in socioeconomic_vars if v in df.columns]\n",
    "    \n",
    "    if len(available_vars) >= 2:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.decomposition import PCA\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(df[available_vars].fillna(df[available_vars].median()))\n",
    "        \n",
    "        pca = PCA(n_components=1)\n",
    "        df['neighborhood_disadvantage_index'] = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        print(f\"✓ Created neighborhood_disadvantage_index (PCA of {len(available_vars)} variables)\")\n",
    "        print(f\"  Explained variance: {pca.explained_variance_ratio_[0]:.2%}\")\n",
    "    \n",
    "    new_features = [col for col in df.columns if col not in merged_df.columns]\n",
    "    print(f\"\\nTotal new features created: {len(new_features)}\")\n",
    "    print(\"New features:\", new_features)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: DATA INTEGRATION RECOMMENDATIONS\n",
    "\n",
    "def recommend_integration_strategy(merged_df):\n",
    "    \"\"\"\n",
    "    Provide specific recommendations for data integration strategy.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RECOMMENDED DATA INTEGRATION STRATEGY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nIMMEDIATE ACTIONS (Use existing data):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"1. Extract all available food access variables from FEA\")\n",
    "    print(\"   - Even though county-level, provides baseline\")\n",
    "    print(\"   - Key variables: SNAP stores, grocery stores, distance to stores\")\n",
    "    print()\n",
    "    print(\"2. Enhance with ACS tract-level data:\")\n",
    "    print(\"   - B22001: SNAP/Food Stamp receipt\")\n",
    "    print(\"   - B08201: Household vehicle availability\")\n",
    "    print(\"   - B19058: Public assistance income\")\n",
    "    print(\"   - B25014: Occupants per room (crowding)\")\n",
    "    print()\n",
    "    print(\"3. Create synthetic features from existing data\")\n",
    "    print(\"   - Population density as urbanicity proxy\")\n",
    "    print(\"   - Economic disadvantage composite\")\n",
    "    print(\"   - Food desert risk score\")\n",
    "    \n",
    "    print(\"\\n SHORT-TERM ENHANCEMENTS (1-2 weeks):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"1. Download USDA Food Access Research Atlas\")\n",
    "    print(\"   - Direct tract-level food access indicators\")\n",
    "    print(\"   - FREE and well-documented\")\n",
    "    print(\"   - High quality government data\")\n",
    "    print()\n",
    "    print(\"2. Scrape OpenStreetMap POI data\")\n",
    "    print(\"   - Use OSMnx or Overpass API\")\n",
    "    print(\"   - Count grocery stores per tract\")\n",
    "    print(\"   - Calculate distance to nearest store from tract centroid\")\n",
    "    print()\n",
    "    print(\"3. Query Google Places API for current store locations\") # deciding against due to computationally heavy + cost\n",
    "    print(\"   - Supplement OSM with more recent data\")\n",
    "    print(\"   - Focus on grocery/supermarket categories\")\n",
    "    \n",
    "    print(\"\\n LONG-TERM ENHANCEMENTS (If resources available):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"1. Access SafeGraph Core Places (free academic license)\")\n",
    "    print(\"   - High-quality commercial POI data\")\n",
    "    print(\"   - Includes visit patterns and demographics\")\n",
    "    print()\n",
    "    print(\"2. Integrate CDC PLACES health outcome data\")\n",
    "    print(\"   - Validate food desert predictions\")\n",
    "    print(\"   - Obesity and diabetes as outcome variables\")\n",
    "    print()\n",
    "    print(\"3. Consider PolicyMap subscription\")\n",
    "    print(\"   - Comprehensive food environment metrics\")\n",
    "    print(\"   - Academic discounts available\")\n",
    "    \n",
    "    print(\"\\n  DATA QUALITY CONSIDERATIONS:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"• County-level FEA limitations:\")\n",
    "    print(\"  - All tracts in same county get identical values\")\n",
    "    print(\"  - Reduces model's ability to distinguish within-county variation\")\n",
    "    print(\"  - May artificially inflate homology features in urban counties\")\n",
    "    print()\n",
    "    print(\"• Recommended approach:\")\n",
    "    print(\"  - Use FEA as baseline/control variables\")\n",
    "    print(\"  - Prioritize tract-level food access data for main analysis\")\n",
    "    print(\"  - Create distance-based features (tract centroid to stores)\")\n",
    "    \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eead85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your merged dataset\n",
    "    merged_df = pd.read_csv('merged_data_cleaned.csv')\n",
    "    \n",
    "    print(\"STEP 1: Analyzing current data limitations...\")\n",
    "    tracts_per_county = explore_fea_county_coverage(None, None, merged_df)\n",
    "    \n",
    "    print(\"\\nSTEP 2: Examining within-county variation...\")\n",
    "    variation_results = analyze_within_county_variation(merged_df)\n",
    "    \n",
    "    print(\"\\nSTEP 3: Identifying existing food desert indicators...\")\n",
    "    indicator_stats, relevant_cols = identify_food_desert_indicators(merged_df)\n",
    "    \n",
    "    print(\"\\nSTEP 4: Documenting alternative data sources...\")\n",
    "    sources = generate_tract_level_recommendations()\n",
    "    \n",
    "    print(\"\\nSTEP 5: Creating synthetic features from existing data...\")\n",
    "    enhanced_df = create_synthetic_tract_features(merged_df)\n",
    "    \n",
    "    print(\"\\nSTEP 6: Providing integration recommendations...\")\n",
    "    recommend_integration_strategy(merged_df)\n",
    "    \n",
    "    # Save enhanced dataset\n",
    "    enhanced_df.to_csv('merged_data_enhanced.csv', index=False)\n",
    "    print(\"\\n✓ Saved enhanced dataset with synthetic features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
